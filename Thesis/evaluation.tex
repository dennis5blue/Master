\section{Evaluation Results}
\label{sec::evaluation}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cityView}
\caption{\label{fig::cityView}City and camera view generated by~\cite{Suicidator,Blender}}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/deploy30_2.pdf}
\caption{\label{fig::deploy30}Camera position and sensing direction}
\end{center}
\end{figure}
%
In this section, we present evaluation results for the proposed scheduling approaches.
In order to evaluate the proposed approach for transmission scheduling, we resort to a 3D modeling software~\cite{Suicidator,Blender} for rendering ``semi-realistic'' city views as the data source.
An example of rendered city is shown in figure~\ref{fig::cityView}.
We then deployed 30 cameras with different view angles in the ``virtual'' city to capture different but correlated views of the city, where the position and sensing direction of those 30 cameras are shown in figure~\ref{fig::deploy30}.

Each camera deployed is configured to take the city snapshot as a $1280 \times 720$ HD image.
To find the amount of encoded bits $H(F_i)$ of each camera, we use a multi-view video coding reference software~\cite{JMVC} to process those regions (treated as an I-frame) of each camera's view.
Afterwards, we perform the multi-view encoding for each pair of cameras and experimentally create the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}.
The parameters for our simulation is listed in table~\ref{tab::evaParameters}.
%
\begin{table}[htb]
\footnotesize
\centering
\begin{tabularx}{0.9\columnwidth}{X|X}
  \hline
  City size & $500m \times 500m$ \\ \\
  Number of cameras & $30$ \\ \\
  Overhearing gap $\rho$ & $1$ \\ \\
  Image resolution & $1280 \times 720$ (HD $720p$) \\ \\
  Focal Length & $35$ ($mm$) \\ \\
  Multiview search range & $32,64,128,256,512$ \\ \\
  Image quantization parameter & $31$ \\ \\
  Coding technique & Context adaptive arithmetic binary coding (CABAC) \\
  \hline
\end{tabularx}
\\
\caption{\label{tab::evaParameters}Parameters for evaluation}
\end{table}
%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/org.pdf}
\caption{Original frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/ref.pdf}
\caption{Reference frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/rec.pdf}
\caption{Reconstructed frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/diff.pdf}
\caption{Reconstructed error}
\end{subfigure}
%
\caption{\label{fig::multiViewImageDemo} Illustration of multiview encoding}
\end{center}
\end{figure}
%

\subsection{Evaluation of Different Search Range}
{\color{red}Show the evaluation result of different search range(results obtained by BB algorithm)}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffRng.pdf}
\caption{\label{fig::txBytes_diffRng} Comparison of different search range of motion estimation}
\end{center}
\end{figure}
Figure~\ref{fig::txBytes_diffRng}

\subsection{Evaluation of Different Branching method}
{\color{red}Show the converged speed of different branching method for BB algorithm.}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareBranching.pdf}
\caption{\label{fig::compareBranching} Comparison of convergence speed for different branching approach}
\end{center}
\end{figure}
Figure~\ref{fig::compareBranching}

\subsection{Evaluation of Different Lower Bound Estimation Technique}
{\color{red}Show the converged speed of different lower bound estimation for BB algorithm.}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareLbEstimation.pdf}
\caption{\label{fig::compareLbEstimation} Comparison of convergence speed for different lower bound estimation methods}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaNumActiveBBNodes.pdf}
\caption{\label{fig::evaNumActiveBBNodes} Comparison of number of active BB nodes for different lower bound estimation methods}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/complexity2.pdf}
\caption{\label{fig::complexity} Required iterations for convergence}
\end{center}
\end{figure}
%
In this chapter, we compare the computational complexity of our proposed BB algorithm with a baseline BB approach.
The pruning stage of the baseline BB approach is based on a greedy approach, and we briefly introduce how it works as follows.
Suppose that we are now considering a sub solution set $\mathcal{S}^t$, cameras are separated into two categories by the baseline lower bound estimation method, including I-frame cameras $\mathcal{I}^t$ and ``not'' I-frame cameras $V \setminus \mathcal{I}^t$.
For an I-frame camera, it is clearly that the encoding cost of this camera can be calculated exactly.
However, for a ``not'' I-frame camera $j$, we consider it as a P-frame camera due to the reason that our goal is to find a lower bound and encoding its image as a P-frame has the possibility to reduce encoded bits compared to encoding its image as an I-frame.
Therefore, the lower bound of encoded cost for camera $j$ can be obtained by a greedy approach, which can be written as:
\begin{equation}
\underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t,
\label{eq::lbGreedy}
\end{equation}
with $h_{jk}^t$ being an element of the cost matrix of $\mathcal{S}^t$.
The reason why we take $k \in V \setminus \mathcal{P}^t$ instead of $k \in V$ is that a camera cannot be referenced as long as it decides to encode its image as a P-frame.
As a summary, the baseline lower bound estimation method is shown in algorithm~\ref{alg::lbEstimation_baseline}.
%
\IncMargin{1em}
\begin{algorithm}[]
 \SetAlgoLined
 \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
 \Input{Partial determined selection vector $\tilde{\mathbf{X}^t}$ of $\mathcal{S}^t$ and cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}}
 \Output{Cost lower bound $lb(\mathcal{S}^t)$ among all sub solution set of $\mathcal{S}^t$}
 \BlankLine
 Initialize $lb(\mathcal{S}^t) \gets 0$\\
 Initialize $\mathcal{I}^t$ by~\eqref{eq::IframeSet}, $\mathcal{P}^t$ by~\eqref{eq::PframeSet} and $\mathbf{H}^t$ by~\eqref{eq::modBBcostMatrix}~\eqref{eq::infColumn} \\
 \For{$i \in \mathcal{I}^t$}
 {
 	Add the cost for I-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + h_{ii}^t$ \\
 }
 \For{$j \in V \setminus \mathcal{I}^t$}
 {
 	Add the cost for candidate P-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + \underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t$ \\
 }
 \caption{\label{alg::lbEstimation_baseline}Baseline lower bound estimation method}
\end{algorithm}
\DecMargin{1em}
%

Note that the lower bound obtained by algorithm~\ref{alg::lbEstimation_baseline} is a loose bound, since the obtained cost might refer to an infeasible reference structure (i.e. $i$ reference $j$ together with $j$ reference $i$).
Therefore, we can claim that our proposed lower bound estimation method can reduce more computational complexity than the baseline approach.
As shown in figure~\ref{fig::compareLbEstimation}, although the two algorithms converge to the same optimal objective value, the required iterations for convergence for those two approaches are definitely different.
That is, more than $98\%$ of iterations can be further reduced if our proposed lower bound estimation technique is applied.
The results thus confirm us that the lower bound estimated by algorithm~\ref{alg::lbEstimation} is a tighter bound so that the optimal solution can be found under lower computational complexity.

Figure~\ref{fig::evaNumActiveBBNodes}
Figure~\ref{fig::complexity} further shows that result for required

\subsection{Evaluation of Different I-frame Selection Algorithms}
{\color{red}Show the evaluation result of different I-frame selection algorithms (BB, proposed MDS, baseline MDS~\cite{MWDS_baseline}).}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffAlg2.pdf}
\caption{\label{fig::txBytes_diffAlg} Comparison of different I-frame selection algorithms}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_BB.pdf}
\caption{\label{fig::refStructure_BB} Proposed BB algorithm}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_MDSbaseline.pdf}
\caption{\label{fig::refStructure_MDSbaseline} Baseline MDS algorithm}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_MDSproposed.pdf}
\caption{\label{fig::refStructure_MDSproposed} Proposed MDS algorithm}
\end{subfigure}
%
\caption{\label{fig::refStructure_threeAlgs} Selected I-frame cameras and their member P-frame cameras}
\end{center}
\end{figure}
Figure~\ref{fig::txBytes_diffAlg}~\ref{fig::refStructure_threeAlgs}

%
%In this subsection, we present the evaluation results of the branch-and-bound algorithm for overhearing source coding.
%Through the overhearing source coding mechanism, each camera can leverage the transmitted frame of previous scheduled cameras for reducing the amount of bits needed to be delivered.
%That is, some correlated information is no longer necessary to be transmitted after processing the overheard frames.
%Based on this idea, the branch-and-bound algorithm is then applied to determine the I-frame transmitters, and we can obtain $35\%$ transmission bits reduction when the searching range of multiview prediction is 32 pixels.
%Moreover, the performance gain becomes better ($55\%$) if the searching range is increased to 512 pixels as shown in figure~\ref{fig::evaSearchRng}.
%Note that the branch-and-bound algorithm is promised to obtained the optimal solution.

%Figure~\ref{fig::imageDemo}~and~\ref{fig::imageDemo2} further demonstrates how the multiview encoder really works.
%Suppose that the original frame in figure~\ref{fig::imageDemo} overhears the reference frame and multiview encoding is provided for reducing the amount of encoded bits.
%It can be shown in figure~\ref{fig::imageDemo2} that the reconstructed frame is almost the same with the original frame.
%Actually, the PSNR of the difference between original frame and reconstructed frame is 36, and hence we can claimed that our correlated image gathering scheme is almost lossless.
%

%\subsection{Evaluation of Convergence}
{%\color{red}Show the evaluation result of required BB iterations (compare proposed lower bound estimation algorithm with the baseline lower bound estimation method)}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/converge2.pdf}
%\caption{\label{fig::evaBBConvergence}Convergence analysis of BB algorithm}
%\end{center}
%\end{figure}
%In addition to getting the optimal transmission schedule, we are also interested in the time complexity of the branch-and-bound algorithm.
%Figure~\ref{fig::evaBBConvergence} shows the upper bound and lower bound of the BB algorithm during each iteration.
%It can be seen that the BB algorithm stops (the optimal solution is obtained) at about  $22000$ iterations, which means that the time complexity is reduced $33\%$ compared to the brute force searching method.
%Therefore, we can claim that our proposed branch-and-bound algorithm can obtain the optimal scheduling solution in an efficient way.
%
%\subsection{Evaluation of P-Frame Scheduling Algorithm}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/pFrameScheduling.pdf}
%\caption{\label{fig::evaPFrameScheduling}Evaluation of different P-frame schedules}
%\end{center}
%\end{figure}
%
\subsection{Evaluation of Different Overhearing Range}
{\color{red}Show the evaluation result of different overhearing range.}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/overRange.pdf}
\caption{\label{fig::evaOverRange}Evaluation of different overhearing range parameter $\rho$}
\end{center}
\end{figure}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/overhearingRange.pdf}
%\caption{\label{fig::evaOverRange}Evaluation of different overhearing range}
%\end{center}
%\end{figure}
%
Figure~\ref{fig::evaOverRange}

\subsection{Evaluation of Multiple Transmission Rounds}
{\color{red}Show the evaluation results for different transmission round.}
\ignore{
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot1}
\caption{Camera 1, round 1}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot1}
\caption{Camera 2, round 1}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot7}
\caption{Camera 1, round 2}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot7}
\caption{Camera 2, round 2}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot3}
\caption{Camera 1, round 3}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot3}
\caption{Camera 2, round 3}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot5}
\caption{Camera 1, round 4}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot5}
\caption{Camera 2, round 4}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot4}
\caption{Camera 1, round 5}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot4}
\caption{Camera 2, round 5}
\end{subfigure}
\caption{\label{fig::imgCapMultiSlots} Image captured at different transmission round}
\end{center}
\end{figure}
} % end ignore
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaMultiSlots2.pdf}
\caption{\label{fig::evaMultiSlots}Evaluation of improvement ratio for different transmission round}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cmuExecTime.pdf}
\caption{\label{fig::evaExecTime}Evaluation of cumulative execution time for different algorithms}
\end{center}
\end{figure}
%
For real-world multi-camera applications, each camera will transmit video streams instead of only one isolated video frame.
As a consequence, in this chapter, we consider the scenario that each camera will transmit its video frames sequentially for multiple transmission round, where the definition of ``one transmission round'' is presented in Chapter~\ref{sec::overallSystemArchi}.
Assume that the scenario we considered has $10$ transmission round, which means that each camera is required to deliver $10$ I-frames to the data aggregator.
Since different transmission rounds mean we make observation at different time instance, it is clearly that the video frames captured by each camera will become different at different transmission round.
In addition, the exact cost matrix will also be changed for different transmission round.
Due to the reasons described above, the improvement ratio of our proposed correlated data gathering scheme (either the branch-and-bound method or the graph approximation approach) will vary as the transmission round changes.

We now consider a scenario having $10$ cameras deployed at intersections of a city.
%where the captured video snapshots of two cameras at different transmission round is shown in figure~\ref{fig::imgCapMultiSlots}.
Three different criteria for dealing with the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix} are now compared in this chapter.
The idea of three different criteria are listed below:
\begin{itemize}
\item \textbf{Static cost matrix}: Indicate the case that the cost matrix does not modified as the transmission round changes.
That is, the data aggregator only calculates the cost matrix for the first transmission round, and the obtained cost matrix will be used for the following $9$ transmission round.
The advantage of this criterion is that it has the lowest computational complexity at the data aggregator since it only requires calculating cost matrix and scheduling cameras once.
However, outdated cost matrix will decrease the performance of our proposed data gathering scheme.
\item \textbf{Dynamic cost matrix (baseline)}: Indicate the case that the cost matrix is dynamically being modified as the transmission round changes, where baseline means that our proposed reestimation criteria introduced in Chapter~\ref{sec::reestimationCriteria} has not been applied.
Therefore, the data aggregator will use a multiview encoder for updating the cost matrix each time when a transmission round is terminated.
The advantage of this criterion is that it can adapt to the scenario that the video streams change rapidly since the cost matrix is updated round by round.
However, frequently calculating cost matrix will lead to very high computational complexity at the data aggregator.
\item \textbf{Dynamic cost matrix (proposed)}:
Indicate the case that the cost matrix is dynamically being modified at some transmission rounds, where the reestimation criteria introduced in Chapter~\ref{sec::reestimationCriteria} is applied for this case.
Intuitively speaking, this case can achieve better performance than static cost matrix and also has lower computational complexity compared to baseline dynamic cost matrix.
\end{itemize}

Figure~\ref{fig::evaMultiSlots} thus confirms our claim of advantages and disadvantages for the above three cases.
Both the results of branch-and-bound algorithm and graph approximation algorithm are shown in this figure.
For the graph approximation algorithm, since it is a heuristic approach and hence it is not promised to obtain the optimal solution.
Therefore, we can observe in figure~\ref{fig::evaMultiSlots} that although the performance of graph approximation can sometimes be very closed to the performance of branch-and-bound algorithm, it happens that there exists a considerable performance gap between these two methods at some transmission round (e.g. round $1$).
Let us now focus on the variation of improvement ratio, it is clearly that the baseline dynamic cost matrix is the upper bound for the improvement ratio since it updates $\mathbf{H}$ for every transmission round.
On the other hand, using static cost matrix is the lower bound for the improvement ratio and we can observe in figure~\ref{fig::evaMultiSlots} that the performance for this case become very bad after round $2$.
However, as long as the improvement ratio decrease badly at round $2$, the long term improvement ratio $\bar{\eta}$~\eqref{eq::updateEta} will decrease.
The decrease of $\bar{\eta}$ will trigger the reestimation of $\mathbf{H}$ so that the performance can be recovered at round $3$.
For the same reason, the result in figure~\ref{fig::evaMultiSlots} indicates that the performance will recover to the ``best'' performance in the next transmission round if the improvement ratio becomes lower than a threshold.

Figure~\ref{fig::evaExecTime}

\subsection{Evaluation of Received Image Quality}
{\color{red}Show the evaluation results for image quality of different transmission round.}
\begin{figure}
\begin{center}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/evaAllPSNR.pdf}
\caption{\label{fig::evaAllPSNR}}
\end{subfigure}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=\columnwidth]{Figures/evaPartialPSNR.pdf}
\caption{\label{fig::evaPartialPSNR}}
\end{subfigure}
\caption{\label{fig::evaMultiRunPSNR} PSNR for reconstructed video frames}
\end{center}
\end{figure}
%
Figure~\ref{fig::evaMultiRunPSNR}