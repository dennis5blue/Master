\section{Evaluation Results}
\label{sec::evaluation}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cityView}
\caption{\label{fig::cityView}City and camera view generated by~\cite{Suicidator,Blender}}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/deploy30_2.pdf}
\caption{\label{fig::deploy30}Camera position and sensing direction}
\end{center}
\end{figure}
%
In this section, we present evaluation results for the proposed scheduling approaches.
In order to evaluate the proposed approach for transmission scheduling, we resort to a 3D modeling software~\cite{Suicidator,Blender} for rendering ``semi-realistic'' city views as the data source.
An example of rendered city is shown in figure~\ref{fig::cityView}.
We then deployed 30 cameras with different view angles in the ``virtual'' city to capture different but correlated views of the city, where the position and sensing direction of those 30 cameras are shown in figure~\ref{fig::deploy30}.

Each camera deployed is configured to take the city snapshot as a $1280 \times 720$ HD image.
To find the amount of encoded bits $H(F_i)$ of each camera, we use a multi-view video coding reference software~\cite{JMVC} to process those regions (treated as an I-frame) of each camera's view.
Afterwards, we perform the multi-view encoding for each pair of cameras and experimentally create the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}.
The parameters for our simulation is listed in table~\ref{tab::evaParameters}.
%
\begin{table}[htb]
\footnotesize
\centering
\begin{tabularx}{0.9\columnwidth}{X|X}
  \hline
  City size & $500m \times 500m$ \\ \\
  Number of cameras & $30$ \\ \\
  Overhearing gap $\rho$ & $1$ \\ \\
  Image resolution & $1280 \times 720$ (HD $720p$) \\ \\
  Focal Length & $35$ ($mm$) \\ \\
  Multiview search range & $32,64,128,256,512$ \\ \\
  Image quantization parameter & $31$ \\ \\
  Coding technique & Context adaptive arithmetic binary coding (CABAC) \\
  \hline
\end{tabularx}
\\
\caption{\label{tab::evaParameters}Parameters for evaluation}
\end{table}
%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/org}
\caption{Original frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/ref}
\caption{Reference frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/rec}
\caption{Reconstructed frame}
\end{subfigure}
%
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/diff}
\caption{Reconstructed error}
\end{subfigure}
%
\caption{\label{fig::multiViewImageDemo} Illustration of multiview encoding}
\end{center}
\end{figure}
%

\subsection{Evaluation of Different Search Range}
{\color{red}Show the evaluation result of different search range(results obtained by BB algorithm)}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffRng.pdf}
\caption{\label{fig::txBytes_diffRng} Comparison of different search range of motion estimation}
\end{center}
\end{figure}
Figure~\ref{fig::txBytes_diffRng}

\subsection{Evaluation of Different Branching method}
{\color{red}Show the converged speed of different branching method for BB algorithm.}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareBranching.pdf}
\caption{\label{fig::compareBranching} Comparison of convergence speed for different branching approach}
\end{center}
\end{figure}
Figure~\ref{fig::compareBranching}

\subsection{Evaluation of Different Lower Bound Estimation Technique}
{\color{red}Show the converged speed of different lower bound estimation for BB algorithm.}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareLbEstimation.pdf}
\caption{\label{fig::compareLbEstimation} Comparison of convergence speed for different lower bound estimation methods}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaNumActiveBBNodes.pdf}
\caption{\label{fig::evaNumActiveBBNodes} Comparison of number of active BB nodes for different lower bound estimation methods}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/complexity2.pdf}
\caption{\label{fig::complexity} Required iterations for convergence}
\end{center}
\end{figure}
%
In this chapter, we compare the computational complexity of our proposed BB algorithm with a baseline BB approach.
The pruning stage of the baseline BB approach is based on a greedy approach, and we briefly introduce how it works as follows.
Suppose that we are now considering a sub solution set $\mathcal{S}^t$, cameras are separated into two categories by the baseline lower bound estimation method, including I-frame cameras $\mathcal{I}^t$ and ``not'' I-frame cameras $V \setminus \mathcal{I}^t$.
For an I-frame camera, it is clearly that the encoding cost of this camera can be calculated exactly.
However, for a ``not'' I-frame camera $j$, we consider it as a P-frame camera due to the reason that our goal is to find a lower bound and encoding its image as a P-frame has the possibility to reduce encoded bits compared to encoding its image as an I-frame.
Therefore, the lower bound of encoded cost for camera $j$ can be obtained by a greedy approach, which can be written as:
\begin{equation}
\underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t,
\label{eq::lbGreedy}
\end{equation}
with $h_{jk}^t$ being an element of the cost matrix of $\mathcal{S}^t$.
The reason why we take $k \in V \setminus \mathcal{P}^t$ instead of $k \in V$ is that a camera cannot be referenced as long as it decides to encode its image as a P-frame.
As a summary, the baseline lower bound estimation method is shown in algorithm~\ref{alg::lbEstimation_baseline}.
%
\IncMargin{1em}
\begin{algorithm}[]
 \SetAlgoLined
 \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
 \Input{Partial determined selection vector $\tilde{\mathbf{X}^t}$ of $\mathcal{S}^t$ and cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}}
 \Output{Cost lower bound $lb(\mathcal{S}^t)$ among all sub solution set of $\mathcal{S}^t$}
 \BlankLine
 Initialize $lb(\mathcal{S}^t) \gets 0$\\
 Initialize $\mathcal{I}^t$ by~\eqref{eq::IframeSet}, $\mathcal{P}^t$ by~\eqref{eq::PframeSet} and $\mathbf{H}^t$ by~\eqref{eq::modBBcostMatrix}~\eqref{eq::infColumn} \\
 \For{$i \in \mathcal{I}^t$}
 {
 	Add the cost for I-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + h_{ii}^t$ \\
 }
 \For{$j \in V \setminus \mathcal{I}^t$}
 {
 	Add the cost for candidate P-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + \underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t$ \\
 }
 \caption{\label{alg::lbEstimation_baseline}Baseline lower bound estimation method}
\end{algorithm}
\DecMargin{1em}
%

Note that the lower bound obtained by algorithm~\ref{alg::lbEstimation_baseline} is a loose bound, since the obtained cost might refer to an infeasible reference structure (i.e. $i$ reference $j$ together with $j$ reference $i$).
Therefore, we can claim that our proposed lower bound estimation method can reduce more computational complexity than the baseline approach.
As shown in figure~\ref{fig::compareLbEstimation}, although the two algorithms converge to the same optimal objective value, the required iterations for convergence for those two approaches are definitely different.
That is, more than $98\%$ of iterations can be further reduced if our proposed lower bound estimation technique is applied.
The results thus confirm us that the lower bound estimated by algorithm~\ref{alg::lbEstimation} is a tighter bound so that the optimal solution can be found under lower computational complexity.

Figure~\ref{fig::evaNumActiveBBNodes}
Figure~\ref{fig::complexity} further shows that result for required

\subsection{Evaluation of Different I-frame Selection Algorithms}
{\color{red}Show the evaluation result of different I-frame selection algorithms (BB, proposed MDS, baseline MDS~\cite{MWDS_baseline}).}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffAlg2.pdf}
\caption{\label{fig::txBytes_diffAlg} Comparison of different I-frame selection algorithms}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_BB.pdf}
\caption{\label{fig::refStructure_BB} Proposed BB algorithm}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_MDSbaseline.pdf}
\caption{\label{fig::refStructure_MDSbaseline} Baseline MDS algorithm}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/refStructure_MDSproposed.pdf}
\caption{\label{fig::refStructure_MDSproposed} Proposed MDS algorithm}
\end{subfigure}
%
\caption{\label{fig::refStructure_threeAlgs} Selected I-frame cameras and their member P-frame cameras}
\end{center}
\end{figure}
Figure~\ref{fig::txBytes_diffAlg}~\ref{fig::refStructure_threeAlgs}

%
%In this subsection, we present the evaluation results of the branch-and-bound algorithm for overhearing source coding.
%Through the overhearing source coding mechanism, each camera can leverage the transmitted frame of previous scheduled cameras for reducing the amount of bits needed to be delivered.
%That is, some correlated information is no longer necessary to be transmitted after processing the overheard frames.
%Based on this idea, the branch-and-bound algorithm is then applied to determine the I-frame transmitters, and we can obtain $35\%$ transmission bits reduction when the searching range of multiview prediction is 32 pixels.
%Moreover, the performance gain becomes better ($55\%$) if the searching range is increased to 512 pixels as shown in figure~\ref{fig::evaSearchRng}.
%Note that the branch-and-bound algorithm is promised to obtained the optimal solution.

%Figure~\ref{fig::imageDemo}~and~\ref{fig::imageDemo2} further demonstrates how the multiview encoder really works.
%Suppose that the original frame in figure~\ref{fig::imageDemo} overhears the reference frame and multiview encoding is provided for reducing the amount of encoded bits.
%It can be shown in figure~\ref{fig::imageDemo2} that the reconstructed frame is almost the same with the original frame.
%Actually, the PSNR of the difference between original frame and reconstructed frame is 36, and hence we can claimed that our correlated image gathering scheme is almost lossless.
%

%\subsection{Evaluation of Convergence}
{%\color{red}Show the evaluation result of required BB iterations (compare proposed lower bound estimation algorithm with the baseline lower bound estimation method)}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/converge2.pdf}
%\caption{\label{fig::evaBBConvergence}Convergence analysis of BB algorithm}
%\end{center}
%\end{figure}
%In addition to getting the optimal transmission schedule, we are also interested in the time complexity of the branch-and-bound algorithm.
%Figure~\ref{fig::evaBBConvergence} shows the upper bound and lower bound of the BB algorithm during each iteration.
%It can be seen that the BB algorithm stops (the optimal solution is obtained) at about  $22000$ iterations, which means that the time complexity is reduced $33\%$ compared to the brute force searching method.
%Therefore, we can claim that our proposed branch-and-bound algorithm can obtain the optimal scheduling solution in an efficient way.
%
%\subsection{Evaluation of P-Frame Scheduling Algorithm}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/pFrameScheduling.pdf}
%\caption{\label{fig::evaPFrameScheduling}Evaluation of different P-frame schedules}
%\end{center}
%\end{figure}
%
\subsection{Evaluation of Different Overhearing Range}
{\color{red}Show the evaluation result of different overhearing range.}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/overhearingRange.pdf}
%\caption{\label{fig::evaOverRange}Evaluation of different overhearing range}
%\end{center}
%\end{figure}
%
\subsection{Evaluation of Multiple Transmission Rounds}
{\color{red}Show the evaluation results for different transmission round.}
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot1}
\caption{Camera 1, round 1}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot1}
\caption{Camera 2, round 1}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot7}
\caption{Camera 1, round 2}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot7}
\caption{Camera 2, round 2}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot3}
\caption{Camera 1, round 3}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot3}
\caption{Camera 2, round 3}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot5}
\caption{Camera 1, round 4}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot5}
\caption{Camera 2, round 4}
\end{subfigure}
%
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam3Slot4}
\caption{Camera 1, round 5}
\end{subfigure}
\begin{subfigure}[b]{0.4\columnwidth}
\includegraphics[width=\columnwidth]{Figures/multiSlots/cam4Slot4}
\caption{Camera 2, round 5}
\end{subfigure}
\caption{\label{fig::imgCapMultiSlots} Image captured at different transmission round}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaMultiSlots2.pdf}
\caption{\label{fig::evaMultiSlots}Evaluation of improvement ratio for different transmission round}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaExecTime.pdf}
\caption{\label{fig::evaExecTime}Evaluation of execution time for different transmission round}
\end{center}
\end{figure}
%
Figure~\ref{fig::imgCapMultiSlots}
Figure~\ref{fig::evaMultiSlots}~\ref{fig::evaExecTime}