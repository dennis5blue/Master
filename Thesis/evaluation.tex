\section{Evaluation Results}
\label{sec::evaluation}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cityView}
\caption{\label{fig::cityView}City and camera view generated by~\cite{Suicidator,Blender}}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/deploy30.pdf}
\caption{\label{fig::deploy30}Camera position and sensing direction}
\end{center}
\end{figure}
%
In this section, we present evaluation results for the proposed scheduling approaches.
In order to evaluate the proposed approach for transmission scheduling, we resort to a 3D modeling software~\cite{Suicidator,Blender} for rendering ``semi-realistic'' city views as the data source.
An example of rendered city is shown in figure~\ref{fig::cityView}.
We then deployed 30 cameras with different view angles in the ``virtual'' city to capture different but correlated views of the city, where the position and sensing direction of those 30 cameras are shown in figure~\ref{fig::deploy30}.

Each camera deployed is configured to take the city snapshot as a $1280 \times 720$ HD image.
To find the amount of encoded bits $H(F_i)$ of each camera, we use a multi-view video coding reference software~\cite{JMVC} to process those regions (treated as an I-frame) of each camera's view.
Afterwards, we perform the multi-view encoding for each pair of cameras and experimentally create the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}.
The parameters for our simulation is listed in table~\ref{tab::evaParameters}.
%
\begin{table}[htb]
\footnotesize
\centering
\begin{tabular}{c||c}
  \hline
  City size & $500m \times 500m$ \\ \\
  Number of cameras & $30$ \\ \\
  Overhearing gap $\rho$ & $1$ \\ \\
  Image resolution & $1280 \times 720$ (HD $720p$) \\ \\
  Focal Length & $35$ ($mm$) \\ \\
  Multiview search range & $32,64,128,256,512$ \\ \\
  Image quantization parameter & $31$ \\ \\
  Coding technique & Context adaptive arithmetic \\
                                  & binary coding (CABAC) \\
  \hline
\end{tabular}
\\
\caption{\label{tab::evaParameters}Parameters for evaluation}
\end{table}

%
\subsection{Evaluation of Different Scheduling Algorithms}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes2.pdf}
\caption{\label{fig::evaSearchRng}Comparison of different scheduling algorithms}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/imageDemo.pdf}
\caption{\label{fig::imageDemo}Original frame and reference frame}
\end{center}
\end{figure}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/imageDemo2.pdf}
\caption{\label{fig::imageDemo2}Reconstructed frame and error}
\end{center}
\end{figure}
%
In this subsection, we present the evaluation results of the branch-and-bound algorithm for overhearing source coding.
Through the overhearing source coding mechanism, each camera can leverage the transmitted frame of previous scheduled cameras for reducing the amount of bits needed to be delivered.
That is, some correlated information is no longer necessary to be transmitted after processing the overheard frames.
Based on this idea, the branch-and-bound algorithm is then applied to determine the I-frame transmitters, and we can obtain $35\%$ transmission bits reduction when the searching range of multiview prediction is 32 pixels.
Moreover, the performance gain becomes better ($55\%$) if the searching range is increased to 512 pixels as shown in figure~\ref{fig::evaSearchRng}.
Note that the branch-and-bound algorithm is promised to obtained the optimal solution.

Figure~\ref{fig::imageDemo}~and~\ref{fig::imageDemo2} further demonstrates how the multiview encoder really works.
Suppose that the original frame in figure~\ref{fig::imageDemo} overhears the reference frame and multiview encoding is provided for reducing the amount of encoded bits.
It can be shown in figure~\ref{fig::imageDemo2} that the reconstructed frame is almost the same with the original frame.
Actually, the PSNR of the difference between original frame and reconstructed frame is 36, and hence we can claimed that our correlated image gathering scheme is almost lossless.
%
\subsection{Evaluation of Convergence}
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/converge2.pdf}
\caption{\label{fig::evaBBConvergence}Convergence analysis of BB algorithm}
\end{center}
\end{figure}
In addition to getting the optimal transmission schedule, we are also interested in the time complexity of the branch-and-bound algorithm.
Figure~\ref{fig::evaBBConvergence} shows the upper bound and lower bound of the BB algorithm during each iteration.
It can be seen that the BB algorithm stops (the optimal solution is obtained) at about  $22000$ iterations, which means that the time complexity is reduced $33\%$ compared to the brute force searching method.
Therefore, we can claim that our proposed branch-and-bound algorithm can obtain the optimal scheduling solution in an efficient way.
%
\subsection{Evaluation of P-Frame Scheduling Algorithm}
%
\subsection{Evaluation of Different Overhearing Range}
