\subsection{Related Work}
\label{sec::relatedWork}
As we mentioned in the previous chapters, the rise of multi-camera networks has prompted researchers to investigate challenging issues in different areas~\cite{VsnChallenges}.
The idea of multi-camera networks can be applied for a wide range of applications, for example, cameras deployed in the distributed video-based surveillance system~\cite{VideoBasedSurveillanceSystem} are responsible for collecting visual data, processing the visual data collaboratively, and transmitting the data to a data aggregator.
However, data transmission in multi-camera networks is considered to be very different from conventional scalar sensor networks.
That is, a huge amount of radio resource, for example, might be required to support a wireless surveillance system to provide real-time transmission of the image/video over wireless communication links.
Besides, the correlation of visual data is also very different from scalar data since even though two cameras are deployed at the same position, different sensing direction will cause them producing different video streams.
To optimize the system performance of multi-camera networks, related works have investigated this topic through various perspectives.
Therefore, before presenting our proposed scenario, we first introduce several related works in this chapter, and the related works are separated in the following four categories: multi-camera networks, resource allocation, visual correlation model, and overhearing source coding.
%
\subsubsection{Multi-camera Networks}
Multi-camera networks have been considered as powerful tools for various safety and security applications for different environments such as highways or subway stations~\cite{MultiCameraNetworksBook}.
Since visual data for those applications often required a huge amount of allocated radio resource for transmission, one popular research topic for the multi-camera networks is how to efficiently encode and deliver distributed visual information collected by cameras.

To address the encoding problem, distributed source coding (DSC)~\cite{SlepianWolf}~\cite{WynerZiv} has been proposed for improving coding efficiency by the spatial correlation among cameras.
%
\subsubsection{Resource Allocation}
%
\subsubsection{Visual Correlation Model}
%
\subsubsection{Overhearing Source Coding}

\subsubsection{OLD}
To reduce the demand on radio resource requirement, related work has proposed the concept of video summary to exploit redundancy among multiple surveillance cameras.
The authors in~\cite{ClusteredSynopsis} propose to cluster similar activities from different cameras into a shorter video summary to improve the efficiency of browsing and searching the video.
The work, however, leaves open how such huge amount of videos can be collected through wireless communication links.
The authors in~\cite{CameraSelection} propose a different approach to reduce the amount of transmitted image data by selecting only a subset of cameras to report their information.
The goal of the selection is to find the set of images that contribute most significantly to the desired observation.
Such a selective report mechanism is different from our work, where the information from all cameras are retained without loss in the overall quality of the data collected at the aggregator.

A different class of approaches to reduce the required radio resource is to apply distributed video coding (DVC)~\cite{DVC} through Slepian-Wolf coding or Wyner-Ziv coding.
In distributed video coding, an encoder encodes individual frames independently, whereas the decoder jointly decodes the encoded frames.
Side information such as previous frames is often needed by the decoder to successfully decode all received frames.
The authors in~\cite{DVCinMVC} extend the concept of distributed video coding to multiview systems, where the side information is generated by exploiting the spatial correlation among different cameras.
Our work, on the other hand, does not incur the complexity at the DVC decoder by leveraging the inherent overhearing capability at the encoders.

The authors in~\cite{SpatialCorrelationModel} propose a spatial correlation model for cameras deployed in a neighborhood area.
In their model, the correlation of two cameras is determined by their location and the difference of their sensing direction.
In reality, however, the camera views are rather complicated and it is often insufficient to model the correlation based only on geometric information.
As demonstrated in~\cite{RealisticModel} based on H.264 multiview video coding, the discrepancy increases as the angular difference between cameras increases.
Since our work is based on real H.264 multiview coding, we do not suffer from the same problem as in~\cite{SpatialCorrelationModel}.
%

Finally, note that the work in~\cite{MLS} has also considered overhearing in wireless multimedia sensor networks.
The model is based on~\cite{SpatialCorrelationModel} and the authors have solved a relaxed integer programming problem to determine the schedule of cameras for energy-efficient transmission.
As we show in chapter~\ref{sec::evaluation}, our proposed \emph{correlation-aware scheduling algorithm} can achieve a better performance without the need to solve the relaxed optimization problem.

%
%
%
In the context of wireless multimedia sensor networks, related work has also applied 
clustered communication for image gathering.
The authors in~\cite{DMCPclustering} formulate a cluster formation problem to maximize the compression gain of images.
They propose a distributed multi-cluster protocol (DMCP) to select a subset of nodes in the network as cluster heads for partitioning the entire network into a set of coding clusters such that the global coding gain is maximized.
However, in order to reduce redundant data transmission at cluster heads, the purpose of clustering cameras in our work is not to maximize the coding gain.
Instead, it is unnecessary for cluster heads to relay collected data.
That is, our goal is to reuse spatial resource so that cameras belong to different clusters can directly transmit their data to the back-end server simultaneously.
%
Besides, similar to the majority of related work on clustering, the problem formulation based purely on graph theory ignores inter-cluster interference and thus results in sub-optimal performance.
We also note that the visual correlation model used in~\cite{DMCPclustering,imageModelCluster} is based on geometry of cameras with consideration of only location and sensing direction.
They refer to the spatial correlation model for cameras deployed in a neighborhood area proposed in~\cite{SpatialCorrelationModel}.
In this model, the correlation of two cameras is determined only by their location and the difference of their sensing direction.
In reality, however, the camera views are rather complicated and it is often insufficient to model the correlation based only on geometric information.
As demonstrated in~\cite{RealisticModel} based on H.264 multiview video coding, the discrepancy increases as the angular difference between cameras increases.
Since our work is based on real H.264 multiview coding, we do not suffer from the same problem as in~\cite{DMCPclustering,imageModelCluster}.
Instead, the image correlation model used in our work is based on actual coding of images and hence might lead to more realistic results.

%
For scheduling and power control in wireless networks, a significant portion of related work such as~\cite{TDMASchedule} constructs a ``conflict-free graph'' for scheduling concurrent transmissions.
However, the concept of the conflict graph is based on the {\em protocol interference model} that considers interference only between a pair of links while ignoring the aggregate interference in the network.
Even for related work such as~\cite{clusterScheduleMinEnergy} that investigates  energy-efficient scheduling, the link communication model is still based on SNR without considering the impact of the interference (i.e. SINR).
%
It has to be noted that in our previous work~\cite{dataCentric} we have proposed {\em ``data-centric'' clustering} for M2M communications.
The objective is to maximize the {\em entropy of data collected} from the cluster structure without regard of the transmission scheduling inside each cluster.
Since the interference model considers only the strongest interference from each cluster, power control in~\cite{dataCentric} is conservative as opposed to the case of joint scheduling and power control considered in this work.

%
For the concept of correlated data gathering, the authors in~\cite{CameraSelection} propose a different approach to reduce the amount of transmitted image data by selecting only a subset of cameras to report their information.
The goal of the selection is to find the set of images that contribute most significantly to the desired observation.
The authors in~\cite{CorrAwareScheduling} further proposed a scheduling algorithm based on the importance of data collected by each cameras, and the transmission of later scheduled cameras might be dropped due to the constraints of wireless radio resource.
Such a selective report mechanism is different from our work, where we not only consider camera selection but also try to reduce the amount of transmitted data for the selected cameras.
%

A different class of approaches to reduce the required radio resource is to apply distributed video coding (DVC)~\cite{DVC} through Slepian-Wolf coding or Wyner-Ziv coding.
In distributed video coding, an encoder encodes individual frames independently, whereas the decoder jointly decodes the encoded frames.
Side information such as previous frames is often needed by the decoder to successfully decode all received frames.
The authors in~\cite{DVCinMVC} extend the concept of distributed video coding to multiview systems, where the side information is generated by exploiting the spatial
correlation among different cameras.
%Our work, on the other hand, does not incur the complexity at the DVC decoder
%by leveraging the inherent overhearing capability at the encoders.
Our work, on the other hand, does not refer to distributed video coding technique, we divide each frame into regions and selects only a portion of regions to be delivered to the aggregator.