\subsubsection{Multiview Video Coding}
\label{sec::MultiviewIntro}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{./Figures/multiCam}
\caption{\label{fig::multiCam}Illustration of multiview videos}
\end{center}
\end{figure}
%
\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{Figures/MVC}
\caption{An example of interview prediction~\cite{MVCoverview}\label{fig::MVC}}
\end{figure}
%
In order to achieve a higher compression ratio for mutli-camera networks, Multiview Video Coding (MVC)~\cite{MVCoverview} has been popularly investigated in literatures.
Multiview videos are the video data that observe the same scene from different position or different sensing directions simultaneously.
An example of multiview videos can be shown in Fig.~\ref{fig::multiCam}, where we can learn in this figure that the captured video streams of the two cameras are similar to each other but with a little bit different.
%We now describe how we define the correlation between multiple cameras, which can be further exploited to leverage spatial correlation while delivering data.
More specifically, camera $i$ and camera $j$ in Fig.~\ref{fig::multiCam} are both observing the same object but from different positions and having different sensing directions, there will cause some overlapped regions between the collected views from the two cameras.
This spatial correlation from neighboring cameras can thus help to reduce the amount of data needed to be delivered.
%With the help of MVC, correlated regions between two images can be encoded with less amount of bits, therefore, the usage of radio resource for communication can be reduced.
In order to exploit the spatial correlation between these views for the delivery of efficient compression, MVC allows the idea of \emph{interview prediction}.
That is, the MVC encoder is able to reference from views captured from nearby cameras during the stage of inter prediction as shown in Fig.~\ref{fig::MVC}.

In Fig.~\ref{fig::MVC}, the GOP produced by camera~$1$ contains an I-frame (or known as the anchor frame) followed by seven B-frames.
Therefore, it means that the video stream of camera$1$ can be decoded at the receiver side by either a H.264 or a MVC decoder, and hence the view of camera $1$ can be considered as the base layer among the five cameras.
Camera $2$ to camera $5$ also uses a similar prediction structure, except that the anchor pictures are now P-frames or B-frames instead of I-frames
The anchor pictures of camera $2$ to camera $5$ will be predicted from an I or P frame of the previous encoded view.
For this reason, only when the frames of camera $1$ is received, the GOP produced by camera $2$ to camera $5$ can finally be decoded.
Inter-view correlation is thus being considered in the prediction structure of Fig.~\ref{fig::MVC}, therefore, it is obvious that the MVC encoder is likely to be more efficiently encoded than using five independent H.264 encoder.
In this thesis, we thus leverage the advantages of MVC to perform correlated data gathering for the multi-camera networks.