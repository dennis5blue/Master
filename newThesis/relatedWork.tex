As we mentioned in the previous chapters, the rise of multi-camera networks has prompted researchers to investigate challenging issues in different areas~\cite{VsnChallenges}.
The idea of multi-camera networks can be applied for a wide range of applications, for example, cameras deployed in the distributed video-based surveillance system~\cite{VideoBasedSurveillanceSystem} are responsible for collecting visual data, processing the visual data collaboratively, and transmitting the data to a data aggregator.
However, data transmission in multi-camera networks is considered to be very different from conventional scalar sensor networks.
That is, a huge amount of radio resource, for example, might be required to support a wireless surveillance system to provide real-time transmission of the image/video over wireless communication links.
Besides, the correlation of visual data is also very different from scalar data since even though two cameras are deployed at the same position, different sensing direction will cause them producing different video streams.
To optimize the system performance of multi-camera networks, related works have investigated this topic through various perspectives.
Therefore, before presenting our proposed scenario, we first introduce several related works in this chapter, and the related works are separated in the following four categories: multi-camera networks, resource allocation, visual correlation model, and overhearing source coding.
%
\subsubsection{Multi-camera Networks}
Multi-camera networks have been considered as powerful tools for various safety and security applications for different environments such as highways or subway stations~\cite{MultiCameraNetworksBook}.
Since visual data for those applications often required a huge amount of allocated radio resource for transmission, some popular research topics for the multi-camera networks include (a) how to intelligently encode distributed visual information collected by cameras and (b) how to efficiently deliver the visual data to a data aggregator.

To address the encoding problem, distributed source coding (DSC)~\cite{SlepianWolf}~\cite{WynerZiv} has been proposed for improving the coding efficiency by exploiting the spatial correlation among nearby cameras.
The idea of distributed source coding is to assume there has no communication among cameras when encoding the visual data, however, the decoder needs to jointly decode the collected video streams and hence the computation complexity is shifted from the encoder to decoder.
The author in~\cite{DVC} further based on the results in~\cite{SlepianWolf}~\cite{WynerZiv} and proposed a new paradigm for video compression through distributed video coding (DVC).
In distributed video coding, an encoder encodes individual frames independently, whereas the decoder jointly decodes the encoded frames.
Side information such as previous frames is often needed by the decoder to successfully decode all received frames.
The authors in~\cite{DVCinMVC} extended the concept of distributed video coding to multiview systems, where the side information is generated by exploiting the spatial correlation among different cameras.
Our work, on the other hand, does not incur the complexity at the DVC decoder by leveraging the inherent overhearing capability at the encoders.

In addition to referring to distributed video coding for improving the efficiency of encoding visual data, some researchers also focus on optimizing the delivery procedure of multiview video streams.
The authors in~\cite{P2Pstreaming} considered how to provide multiview video streaming over a peer-to-peer (P2P) network.
They proposed a streaming protocol such that each view of the multiview video is transmitted over an independent P2P streaming tree.
Although the streaming protocol in~\cite{P2Pstreaming} is less affected by the packet loss while delivering data, the coding efficiency can still be improved since they assume that different paths are independent with each other.
Besides, some researches focus on selective streaming for the sake of reducing bandwidth requirement during data transmission.
The work in~\cite{ClientDrivenStreaming} introduced a client-driven multiview streaming system that allows users to interactively watch 3D video.
The idea is that only the views which are required to display at the user's side are transmitted through the internet.
Our work, on the other hand, does not incur information loss at the receiver side since we assume all cameras are required to deliver its data.

For exploiting redundancy among multiple surveillance cameras, the authors in~\cite{ClusteredSynopsis} propose to cluster similar activities from different cameras into a shorter video summary to improve the efficiency of browsing and searching the video.
The work, however, leaves open how such huge amount of videos can be collected through wireless communication links.
The authors in~\cite{CameraSelection} propose a different approach to reduce the amount of transmitted image data by selecting only a subset of cameras to report their information.
The goal of the selection is to find the set of images that contribute most significantly to the desired observation.
The authors in~\cite{CorrAwareScheduling} further proposed a scheduling algorithm based on the importance of data collected by each cameras, and the transmission of later scheduled cameras might be dropped due to the constraints of wireless radio resource.
Such a selective report mechanism is different from our work, where the information from all cameras are retained without loss in the overall quality of the data collected at the aggregator.
%
\subsubsection{Resource Allocation}
Problem of resource allocation for multi-camera networks is also investigated in literature.
%
In~\cite{MWSNresourceAllocation}, the authors considered the problem of capturing and transmitting the video streams of several distributed cameras to an aggregator  over a wireless network.
Since the multimedia data needs to be delivered in real-time under limited network resources, they claimed that the resource allocation solutions for multi-camera networks need to consider both the dynamic source characteristics and network conditions, rather than always relying on steady-state conditions.
%
The authors in~\cite{rateAllocationForVideo} also focus on the resource allocation scheme of multiple cameras under ad-hoc networks.
In ad-hoc networks, different cameras share and compete for the same network resources (e.g. frequency band).
Therefore, a rate allocation algorithm is required to balance the available resources among multiple cameras in a fair and efficient manner.
Besides, the authors also claimed that it is desirable to have a distributed resource allocation scheme such that the overhead of control messages can be reduced since cameras do not require to collect global information of the network under the distributed resource allocation scheme.
%

For correlated multimedia networks, the authors in~\cite{AdaptiveCrossLayerRA} considered the resource allocation problem for uplink transmission of correlated video sources, where multiple sources stream live video to the base station over a shared wireless channel.
They proposed a solution for an optimization problem such that the weighted sum of
received quality of all videos can be maximized by exploiting source correlation at the decoder in case of missing data.
The goal of their problem is to find the optimal coding choice, power assignment and packet selection.
By modelling the quality of a decoded video as a piecewise linear function of qualities of the most correlated views, their problem can be simplified to a convex from with linear constraint, therefore, it can be solved in an efficient way.
Our work, on the other hand, does not focus on the distortion of videos, since we aim to deliver all video streams and hence our proposed methods will not cause so much distortion at the decoder.
%We present a high-level framework for resource-distortion optimization. The framework can be used for jointly considering factors across network layers, including source coding, channel resource allocation, and error concealment. For example, resources can take the form of transmission energy in a wireless channel, and transmission cost in a DiffServ-based Internet channel. This framework can be used to optimally trade off resource consumption with end-to-end video quality in packet-based video transmission~\cite{efficientRAforVideo}.
%
\subsubsection{Visual Correlation Model}
The authors in~\cite{SpatialCorrelationModel} propose a spatial correlation model for cameras deployed in a neighborhood area.
In their model, the correlation of two cameras is determined by their location and the difference of their sensing direction.
In reality, however, the camera views are rather complicated and it is often insufficient to model the correlation based only on geometric information.
As demonstrated in~\cite{RealisticModel} based on H.264 multiview video coding, the discrepancy increases as the angular difference between cameras increases.
Since our work is based on real H.264 multiview coding, we do not suffer from the same problem as in~\cite{SpatialCorrelationModel}.
%
They refer to the spatial correlation model for cameras deployed in a neighborhood area proposed in~\cite{SpatialCorrelationModel}.
In this model, the correlation of two cameras is determined only by their location and the difference of their sensing direction.
In reality, however, the camera views are rather complicated and it is often insufficient to model the correlation based only on geometric information.
As demonstrated in~\cite{RealisticModel} based on H.264 multiview video coding, the discrepancy increases as the angular difference between cameras increases.
Since our work is based on real H.264 multiview coding, we do not suffer from the same problem as in~\cite{DMCPclustering,imageModelCluster}.
Instead, the image correlation model used in our work is based on actual coding of images and hence might lead to more realistic results.
%
\subsubsection{Overhearing Source Coding}
Exploiting the possibility of overhearing for data reduction is investigated in literature, and the overhearing source coding scheme can be applied in many different areas by the cooperation of jointly encoding distributed source nodes.
%
For instance, the authors in~\cite{BodyAreaSensorNetwork} considered the capability of overhearing in the body-area sensor networks.
On the one hand, the wearable sensors deployed on a human body are responsible for tracking human motions, and hence the captured data for those sensors usually exists very high levels of redundancy and even strong temporal and spatial correlations~\cite{SpatialCorrInBodySensorNetwork}.
On the other hand, sensor nodes in the body-sensor networks are likely fully connected and hence it is possible for nodes to overhear each other.
The idea is that each sensor node is conducted in advance to learn the temporal and spatial correlations of sensing data.
After that, a schedule of sensor nodes is determined to represent the transmission order of each node so that the later scheduled node can refer to the data of previous scheduled node during data compression.
Based on the proposed algorithm in~\cite{BodyAreaSensorNetwork}, the authors claimed that their overhearing source coding scheme can reduce more than 70 percent of redundant transmission.
%
Besides, the authors in~\cite{InterSessionCoding} also considered the problem of overhearing source coding for improving coding gains.
They focus on the scenario of a inter-session network coding in wireless ad-hoc or mesh networks, where the relay nodes are able to combine overheard packets for increasing the network throughput.
The transmission range of each node is also investigated in their work by adapting the transmission rate.
That is, a node can increase the overhearing range for the sake of enabling additional opportunities for coding and increased the overall network throughput.
For solving the target problem in~\cite{InterSessionCoding}, a joint optimization problem for determining the transmission rate and coding scheme is formulated and an algorithm for a simplified pairwise network coding problem is further proposed.
%
The considerable performance gain in~\cite{BodyAreaSensorNetwork}~and~\cite{InterSessionCoding} thus motivates us to investigate the overhearing source coding scheme for high correlated networks.
%
%The technique of controlling the transmission power for adjusting the number of nodes that can overhear transmission is further exploited in~\cite{BridgeMonitoring}.
%In~\cite{SpatialCorrInBodySensorNetwork} discusses the application in Human body motions, which is an extension from\cite{BodyAreaSensorNetwork} to exploit more overhearing nodes. It considers node $v_i$ to compress motion data by allowing it to overhear a set $S_i$ containing most $\kappa$ others nodes, and sends averagely $c(v_i|S_i)$ size of data. It discusses the minimizing of transmission cost by taking use of the conditional entropy as an optimal rate, and propose a solution based on finding the minimum cost DAG for it. It shows finding the minimum cost DAG for $\kappa > 2$ is a NP-hard problem and proposes a heuristic greedy cycle breaker algorithm for solving the problem. Experimental results show that such approach is quite close to the optimum in the motion data application.
%

In addition to the scalar sensor networks, the overhearing source coding scheme can also be applied to the wireless multimedia sensor networks.
The work in~\cite{imageModelCluster} exploits overhearing for visual correlation based image gathering.
Each camera in their target scenario is allowed to overhear transmission from one camera and then reduce the power consumption for transmitting its image data.
Their goal is to determine a transmission schedule for the cameras such that the energy consumption of those cameras is minimized by letting highly correlated cameras perform differential coding (e.g. P-frame encoding) to reduce the delivered data.
For this purpose, an approximation and heuristic algorithm is proposed for solving the scheduling problem by taking the camera settings (e.g. position or sensing direction) as the inputs of algorithm.
Our work, on the other hand, does not make approximations when determining the transmission schedule since we refer to a realistic video encoder when generating input information.
%