\section{Centralized Correlated Data Gathering for Wireless Multi-Camera Networks}
\label{sec::protocolDesign}
As we present in Chapter~\ref{sec::OSC} and Chapter~\ref{sec::proposedAlgs} about our proposed data gathering scheme to exploit inter-view correlation among neighboring cameras, we further describe how the proposed scheme can be applied to real-world multi-camera networks in this chapter.
First of all, we will show our modifications about the multi-camera networks so that our proposed correlated data gathering scheme can fit in the system.
Then, we will give an overall explanation about the system architecture, including how to get the required control information and when it should be updated.
%
%\subsection{Modified Motion Estimation Technique}
%\begin{figure}
%\begin{subfigure}[b]{\columnwidth}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/motionEstimation.pdf}
%\caption{\label{fig::originalME}Conventional motion estimation technique}
%\end{center}
%\end{subfigure}
%\begin{subfigure}[b]{\columnwidth}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/modifiedMotionEstimation.pdf}
%\caption{\label{fig::modifiedME}Modified motion estimation technique}
%\end{center}
%\end{subfigure}
%\caption{\label{fig::originalAndModifiedME}Demonstration motion estimation technique in multiview video coding}
%\end{figure}
%
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/biased.pdf}
%\caption{\label{fig::biased}Experiment result of different biased pixels}
%\end{center}
%\end{figure}
{%\color{red} Explain conventional motion estimation technique and our modified motion estimation in JMVC.}
%As we mentioned in the previous chapter, when two cameras are observing the same area but having different sensing direction, then the collected image might just be a shifted image from the other one.
%Therefore, it motivates us to modify the conventional motion estimation technique so that we can have a larger possibility to find a correlated macroblock under a given search range.
%The idea of our modified motion estimation technique is shown in figure~\ref{fig::modifiedME}, where we shift the search region by the value $\kappa$ estimated from equation~\eqref{eq::biasedPixels}.
%Figure~\ref{fig::biased}
%
\subsection{Correlated Image Gathering for Multi-Camera Networks}
As we mentioned before, the encoding structure for a camera is presented in Chapter~\ref{sec::H264CompressionIntro}, and the timeline for GOPs is also shown in Fig.~\ref{fig::baselineGOP}.
Therefore, the encoding structure for multi-camera networks can thus be extended directly from Fig.~\ref{fig::baselineGOP}, which is shown in Fig.~\ref{fig::multiCamGOP_original}.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/multiCamGOP_original.pdf}
\caption{\label{fig::multiCamGOP_original}Group of pictures for non-cooperative multi-camera networks}
\end{center}
\end{figure}
%
Note that we assume that the time slot for transmitting I-frames of each cameras is synchronized in this thesis, where this assumption can be done by any existing synchronization mechanisms in LTE or LTE-A.
Besides, we also require that the base station will know the connectivity of the whole network.
However, there has no cooperation between nearby cameras when encoding video streams if the encoding structure shown in Fig.~\ref{fig::multiCamGOP_original} is used for multi-camera networks, and hence some redundant data might still be encoded.
In order to remove such redundancy, we modify the encoding structure and show our proposed cooperative encoding structure in Fig.~\ref{fig::multiCamGOP}.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/multiCamGOP.pdf}
\caption{\label{fig::multiCamGOP}Group of pictures for cooperative multi-camera networks}
\end{center}
\end{figure}
%

In our proposed method, it is not required for all GOP to start with an I-frame.
That is, at the beginning of each cameras' GOP, only a portion of cameras are selected to encode it video frame as an I-frame, where the selection are done by our proposed \emph{I-frame selection algorithms} as presented in Chapter~\ref{sec::proposedBBAlg} and~\ref{sec::graphApprox}.
After the selection, the remaining P-frames will reference from its most correlated I-frame for removing redundant information.
Note that since the captured video frames will vary as the time changed, it is thus necessary for the data aggregator to update the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix} from time to time in order to prevent from using outdated information for the determination of transmission schedule.
However, frequently recalculate the cost matrix will cause too much computational complexity at the data aggregator, and hence the latency might be increased.
Therefore, \emph{when} should the aggregator update the cost matrix $\mathbf{H}$ thus become one of the main issue to be discussed when applying the correlated data gathering scheme to real-world applications, and we will introduce our proposed criterion for recalculating $\mathbf{H}$ in the followings.
%
\subsection{Overall System Architecture}
\label{sec::overallSystemArchi}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/TxOverview2.pdf}
\caption{\label{fig::txOverview}Demonstration of data transmission scheme}
\end{center}
\end{figure}
%
Before presenting our proposed recalculation criteria, we first show the timeline of the overall system architecture in Fig.~\ref{fig::txOverview}.
Our proposed data gathering scheme consists of three different phases, which includes the \emph{correlation estimation phase} (CE), \emph{transmission scheduling phase} (TS) and \emph{data transmission phase}.
Note that the first two phases (correlation estimation phase and transmission scheduling phase) are done by the data aggregator, and the determined cameras schedule can maintain for several rounds.
Since Fig.~\ref{fig::txOverview} only gives a big picture of our proposed data gathering scheme, we will thus illustrate these three phases more detailed in the followings.
%
\subsubsection{Correlation Estimation (CE) Phase}
During the \emph{correlation estimation phase}, the data aggregator is responsible for calculating the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix} by the received video frames of the preceding data transmission phase.
Note that our proposed correlated data gathering scheme is only applied for I-frames of each camera (i.e. some I-frames in Fig.~\ref{fig::multiCamGOP_original} can be encoded as P-frames as shown in Fig.~\ref{fig::multiCamGOP}), which means that the procedure for encoding P-frames of the H.264 baseline profile is not changed in our proposed data gathering scheme.
Therefore, the calculation of $\mathbf{H}$ should based on the received I-frames (or ``used to'' be I-frames if our scheme is not applied) of each camera.

To start, we will reconstruct those I-frames (or ``used to'' be I-frames) received from the preceding transmission.
Then, the estimation of $\mathbf{H}$ can be divided into the following two parts.
For diagonal elements $h_{11},\cdots,h_{|V||V|}$, their value can be obtained directly by the I-frame size of the video frame of each camera.\
For non-diagonal elements, for instance, $h_{ij}$, ${i \neq j}$, the value is calculated by using the I-frame of camera $j$ for reference to encode the I-frame of camera $i$.
This is done by the multiview encoder at the data aggregator, and ${(|V|-1) \times (|V|-1)}$ times of multiview encoding procedure is required for obtaining all elements of $\mathbf{H}$.
Therefore, it is not efficient for the data aggregator to perform correlation estimation too frequently, and we will describe in Chapter~\ref{sec::dataTransmissionPhase} when the data aggregator will estimate correlation among cameras.
%
\subsubsection{Transmission Scheduling (TS) Phase}
During the \emph{transmission scheduling phase}, the data aggregator will refer to either the branch-and-bound I-frame selection algorithm (presented in Chapter~\ref{sec::proposedBBAlg}) or the graph approximation I-frame selection algorithm (introduced in Chapter~\ref{sec::graphApprox}) for the determination of I-frame cameras.
After that, the idea of P-frame association described in Chapter~\ref{sec::PFrameScheduling} will be applied for choosing reference frame for those P-frame cameras.
As long as the transmission scheduling phase is done, each camera will allocate one dedicated time slot for delivering its data to the aggregator as shown in the bottom of Fig.~\ref{fig::txOverview}.
The determined camera schedule will last for several rounds of transmission, and the schedule will only be changed when the cost matrix $\mathbf{H}$ becomes different.
%
\subsubsection{Data Transmission Phase}
\label{sec::dataTransmissionPhase}
The \emph{data transmission phase} of our scheme is partitioned into several rounds of transmission due to the reason that frequently calculating $\mathbf{H}$ will lead to very high computational complexity.
In this thesis, the definition of ``one transmission round'' is to deliver one GOP of all cameras to the data aggregator, where a GOP may consists of several video frames.
Therefore, partitioning the data transmission phase into several transmission rounds means that the estimated $\mathbf{H}$ will last for the transmission of more than one GOPs, and only be reestimated until it is thought to be outdated.
Note that since we assume that the I-frames of each camera is perfectly synchronized, the number of video frames contained in one GOP of each camera is also equalled.
Therefore, one transmission round can further be separated into several parts, start with the transmission of the GOP of first scheduled camera and end up with the transmission of the GOP of the last scheduled camera as shown in Fig.~\ref{fig::txOverview}.
For the transmission of each camera, all the video frames of GOP will be delivered to the data aggregator sequentially.

%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.65\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/GOPexample.pdf}
\caption{\label{fig::txRoundExampleGOP}Group of pictures}
\end{subfigure}
\begin{subfigure}[b]{0.95\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/txRoundExample2.pdf}
\caption{\label{fig::txRoundExampleTx}Illustration of one transmission round}
\end{subfigure}
\caption{\label{fig::txRoundExample}A three cameras example}
\end{center}
\end{figure}
%
Fig.~\ref{fig::txRoundExample} gives an example of how video frames are scheduled within one transmission round.
Suppose that the network now contains three cameras, and the GOP of each cameras all have four video frames, where the reference structure is shown in Fig.~\ref{fig::txRoundExampleGOP}.
In our example, camera $1$ is selected as I-frame camera whereas camera $2$ and $3$ are P-frame camera and they both reference from camera $1$.
Therefore, the starting I-frame of camera $2$ and $3$ will become P-frame by referencing the starting I-frame of camera $1$.
To proceed, assume that the determined cameras schedule is $1 \rightarrow 2 \rightarrow 3$ in this example.
In this way, the data delivery procedure will start from transmitting all videos frames of camera $1$'s GOP as shown in Fig.~\ref{fig::txRoundExampleTx}, where the number shown at the lower right side of each video frames indicates the index of this frame in its corresponding GOP.
After the transmission of camera $1$ is done, camera $2$ will start its transmission, and then camera $3$, where the the first video frame of camera $2$ and $3$ will both reference from the I-frame of camera $1$.
As long as camera $3$ finishes its transmission, this transmission round is ended.
%
\subsubsection{Proposed Reestimation Criteria}
\label{sec::reestimationCriteria}
Based on the ideas presented in the previous chapters, we now present our proposed criterion for the reestimation of $\mathbf{H}$.
Two extreme cases for reestimating $\mathbf{H}$ are listed below:
\begin{itemize}
\item Estimate $\mathbf{H}$ at the end of every transmission round (i.e. update $\mathbf{H}$ after delivering one GOP).
\item Estimate $\mathbf{H}$ only at the end of first transmission round (i.e use the same $\mathbf{H}$ for delivering all GOPs).
\end{itemize}
However, the two cases above both have significant drawback.
For the former case, the data aggregator will suffer from too much computational complexity, whereas for the later one, outdated cost matrix $\mathbf{H}$ will decrease the performance of the overhearing source coding technique.
Our proposed criteria, on the other hand, is a more balanced method so that we can prevent from having those two disadvantages listed above.

Denote $\eta_i^k$ as the improvement ratio of camera $i$ at transmission round $k$ as:
\begin{align}
&\eta_i^k = \nonumber \\
&\frac{
\left( \begin{tabular}{c}
\text{Amount of encoded} \\
\text{bits of camera $i$ at} \\
\text{round $k$ if it is} \\
\text{independently encoded}
\end{tabular}
-
\begin{tabular}{c}
\text{Amount of encoded} \\
\text{bits of camera $i$ at} \\
\text{round $k$ if overhearing} \\
\text{source coding technique} \\
\text{is applied}
\end{tabular} \right)
}{
\left( \begin{tabular}{c}
\text{Amount of encoded} \\
\text{bits of camera $i$ at} \\
\text{round $k$ if it is} \\
\text{independently encoded}
\end{tabular} \right)
}.
\label{eq::defImproveRatio}
\end{align}
Besides, we also denote $\bar{\eta}$ as the average long term improvement ratio of all cameras, which is updated by a weighted sum procedure at the end of every transmission rounds.
Suppose that now the transmission of round $k$ ends, then $\bar{\eta}$ is updated as:
\begin{equation}
\bar{\eta} = \alpha \frac{1}{|V|} \sum_{i=1}^{|V|} \eta_i^k + (1-\alpha) \bar{\eta},
\label{eq::updateEta}
\end{equation}
where $0 \leq \alpha \leq 1$ is the smoothing parameter introduced for the update procedure.
Our proposed reestimation criteria is thus based on $\bar{\eta}$ defined in equation~\eqref{eq::updateEta}.
That is, if $\bar{\eta}$ becomes smaller after the transmission of round $k$, then the \emph{data transmission phase} is ended after transmission round $k$ since it is possible that the cost matrix $\mathbf{H}$ becomes outdated for the determination of transmission schedule.
Therefore, the \emph{correlation estimation phase} and the \emph{transmission scheduling phase} will be performed before the transmission of round $k+1$, and hence a new, appropriate cost matrix $\mathbf{H}$ can be used for scheduling cameras of  transmission round $k+1$.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/overallArchitecture.pdf}
\caption{\label{fig::overallArchitecture}Flowchart for overall proposed system architecture}
\end{center}
\end{figure}
%
As a summary, we show the overall proposed system architecture in Fig.~\ref{fig::overallArchitecture}.