\subsection{Multiview Video Coding}
\label{sec::MultiviewIntro}
%
In order to achieve a higher compression ratio for multi-camera networks, Multiview Video Coding (MVC)~\cite{MVCoverview} has been popularly investigated in literatures.
Multiview videos are the video data that observe the same scene from different position or different sensing directions simultaneously.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{./Figures/multiCam}
\caption{\label{fig::multiCam}Illustration of multiview videos}
\end{center}
\end{figure}
%
An example of multiview videos can be shown in Fig.~\ref{fig::multiCam}, where we can learn in this figure that the captured video streams of the two cameras are similar to each other but with a little bit different.
More specifically, camera $i$ and camera $j$ in Fig.~\ref{fig::multiCam} are both observing the same object but from different positions and having different sensing directions, therefore, it will cause some overlapped regions between the collected frames from the two cameras.
This spatial correlation from neighboring cameras can thus help to reduce the amount of data needed to be delivered.
In order to exploit the spatial correlation between these views for the delivery of efficient compression, MVC allows the idea of \emph{interview prediction}.
That is, the MVC encoder is able to reference from views captured from nearby cameras during the stage of inter prediction as shown in Fig.~\ref{fig::MVC}.
%
\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{Figures/MVCIntro.pdf}
\caption{An example of interview prediction\label{fig::MVC}}
\end{figure}
%

In Fig.~\ref{fig::MVC}, the GOP produced by camera~$1$ contains an I-frame (or known as the key frame) followed by seven B-frames~\cite{HierarchicalBs}.
Therefore, it means that the video stream of camera~$1$ can be decoded at the receiver side by either a H.264 or a MVC decoder, and hence the view of camera $1$ can be considered as the base layer among the five cameras.
Camera~$2$ to camera~$5$ also uses a similar prediction structure, except that their key frames are now P-frames or B-frames instead of I-frames.
The key frames of camera~$2$ to camera~$5$ will be predicted from an I or P frame of the previous encoded view.
For this reason, only when the frames of camera~$1$ is received, the GOP produced by camera~$2$ to camera~$5$ can finally be decoded.
Inter-view correlation is thus being considered in the prediction structure of Fig.~\ref{fig::MVC}, therefore, it is obvious that the MVC encoder is likely to be more efficiently encoded than using five independent H.264 encoder.
In this thesis, we thus leverage the advantages of MVC to perform correlated data gathering for the multi-camera networks.