\section{Performance Evaluation}
\label{sec::evaluation}
In this chapter, we show the evaluation results in terms of various observation points of our proposed approaches for correlated data gathering.
In order to evaluate the proposed approaches for multi-camera networks, we resort to a 3D modeling software~\cite{Suicidator,Blender} for rendering ``semi-realistic'' city views as the data source.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cityView}
\caption{\label{fig::cityView}City and camera view generated by~\cite{Suicidator,Blender}}
\end{center}
\end{figure}
%
An example of the rendered city is shown in Fig.~\ref{fig::cityView}.
We then deployed $30$ cameras with different view angles in the ``virtual'' city to capture different but correlated views of the city, where the position and sensing direction of those $30$ cameras are shown in Fig.~\ref{fig::deploy30}.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/deploy30_2.pdf}
\caption{\label{fig::deploy30}Camera position and sensing direction}
\end{center}
\end{figure}
%

Each camera deployed is configured to take the city snapshot as a $1280 \times 720$ HD image.
To find the amount of encoded bits $H(F_i)$ of each camera, we use a multi-view video coding reference software~\cite{JMVC} to process the image (treated as an I-frame) of each camera's view.
Afterwards, we perform the multi-view encoding (treated as a P-frame) for each pair of cameras and experimentally create the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}.
We note that the multi-view encoding does not decrease the image quality as shown in Fig.~\ref{fig::multiViewImageDemo}, where we can learn in this figure that the reconstructed frame is almost equalled to the original frame.
%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/org.pdf}
\caption{Original frame}
\end{subfigure}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/ref.pdf}
\caption{Reference frame}
\end{subfigure}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/rec.pdf}
\caption{Reconstructed frame}
\end{subfigure}
\begin{subfigure}[b]{0.45\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/diff.pdf}
\caption{Reconstructed error}
\end{subfigure}
\caption{\label{fig::multiViewImageDemo} Illustration of multiview encoding}
\end{center}
\end{figure}
%
Therefore, we can claim that our proposed correlated data gathering scheme is almost ``lossless'' with the advantage for reducing the amount of encoded bits.
The other parameters for our simulation is listed in table~\ref{tab::evaParameters}.
%
%
\begin{table*}[htb]
\footnotesize
\centering
\begin{tabularx}{0.9\textwidth}{c|c|X}
  \hline
  Type &Parameter &Setting \\
  \hline
  \hline
  \multirow{3}{*}
  {Network topology} &City radius &$500m$ \\
       &Number of cameras &$30$ \\
       &Position of data aggregator &$(0,0)$ \\
       
  \hline
  \multirow{2}{*}
  {Algorithm parameter} &$\rho$ &$1$ \\
  	&$\alpha$ &$0.9$ \\
  \hline
  \multirow{6}{*}
  {Video encoder} &Image resolution &$1280 \times 720$ (HD $720p$) \\ 
   &Camera focal length &$36 (mm)$ \\ 
   &Camera sensor size &$35 (mm)$ \\ 
   &Multiview search range &$32,64,128,256,512$ \\
   &Image quantization parameter &$31$ \\
   &Coding technique &Context adaptive arithmetic binary coding (CABAC) \\
  \hline
\end{tabularx}
\\
\caption{\label{tab::evaParameters}Parameters for evaluation}
\end{table*}
%

\subsection{Evaluation of Different Search Range}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffRng.pdf}
\caption{\label{fig::txBytes_diffRng} Comparison of different search range of motion estimation}
\end{center}
\end{figure}
Before comparing our proposed algorithms with some baseline approaches, we first show the impact of using different search range while performing the multiview encoding procedure in this chapter, where the results are obtained by our proposed BB algorithm.
As shown in Fig.~\ref{fig::txBytes_diffRng}, it is obvious that larger search range will lead to a better performance of the overhearing source coding technique since more correlated macroblock might be found if the searching range of motion estimation becomes larger.
However, we also need to mention that the search range might be increased carefully in order to prevent from causing too much computational complexity at the data aggregator.
Note that the time complexity of the baseline motion estimation in H.264 is $\mathcal{O}(N^2)$ since both horizontal direction and vertical direction are required to be searched.
Therefore, we can claim that the complexity will increase quadratically as the search range becomes larger.

\subsection{Evaluation of Proposed Branch and Bound Algorithm}
In this chapter, we show the several evaluation results of the proposed BB algorithm.
That is, we compare our proposed ``branching'' and ``bounding'' policy with some baseline approaches, and show that our method can outperform those baseline approaches.

\subsubsection{Evaluation of Different Branching Methods}
%{\color{red}Show the converged speed of different branching method for BB algorithm.}
To start, we first show the benefit of using our proposed metric compared to applying the depth first searching method in this chapter.
Note that as we mentioned in Chapter~\ref{sec::proposedBBBranchingPolicy}, the determination of which branch in the enumeration tree should be traverse first can be decided by our proposed branching metric~\eqref{eq::branchingMetric}.
For the depth first searching, although this method is popularly being used in the BB algorithm, it does not consider which node has the higher probability to contain a better solution.
Therefore, it might require more iterations to obtain a good enough objective value as shown in Fig.~\ref{fig::compareBranching}.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareBranching.pdf}
\caption{\label{fig::compareBranching} Comparison of convergence speed for different branching approach}
\end{center}
\end{figure}
%
Our proposed branching metric, on the other hand, consider the estimated lower bound of each node in the enumeration tree, and hence fewer iteration is needed for converging to the optimal solution.

\subsubsection{Evaluation of Different Lower Bound Estimation Techniques}
%{\color{red}Show the converged speed of different lower bound estimation for BB algorithm.}
%
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/evaNumActiveBBNodes.pdf}
%\caption{\label{fig::evaNumActiveBBNodes} Comparison of number of active BB nodes for different lower bound estimation methods}
%\end{center}
%\end{figure}
In this chapter, we compare the computational complexity of our proposed BB algorithm with a baseline BB approach.
The pruning stage of the baseline BB approach is based on a greedy approach, and we briefly introduce how it works as follows.
Suppose that we are now considering a sub solution set $\mathcal{S}^t$, cameras are separated into two categories by the baseline lower bound estimation method, including I-frame cameras $\mathcal{I}^t$ and ``not'' I-frame cameras $V \setminus \mathcal{I}^t$.
For an I-frame camera, it is clearly that the encoding cost of this camera can be calculated exactly.
However, for a ``not'' I-frame camera $j$, we consider it as a P-frame camera due to the reason that our goal is to find a lower bound and encoding its image as a P-frame has the possibility to reduce encoded bits compared to encoding its image as an I-frame.
Therefore, the lower bound of encoded cost for camera $j$ can be obtained by a greedy approach, which can be written as:
\begin{equation}
\underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t,
\label{eq::lbGreedy}
\end{equation}
with $h_{jk}^t$ being an element of the cost matrix of $\mathcal{S}^t$.
The reason why we take $k \in V \setminus \mathcal{P}^t$ instead of $k \in V$ is that a camera cannot be referenced as long as it decides to encode its image as a P-frame.
As a summary, the baseline lower bound estimation method is shown in algorithm~\ref{alg::lbEstimation_baseline}.
%
\IncMargin{1em}
\begin{algorithm}[]
 \SetAlgoLined
 \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
 \Input{Partial determined selection vector $\tilde{\mathbf{X}^t}$ of $\mathcal{S}^t$ and cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix}}
 \Output{Cost lower bound $lb(\mathcal{S}^t)$ among all sub solution set of $\mathcal{S}^t$}
 \BlankLine
 Initialize $lb(\mathcal{S}^t) \gets 0$\\
 Initialize $\mathcal{I}^t$ by~\eqref{eq::IframeSet}, $\mathcal{P}^t$ by~\eqref{eq::PframeSet} and $\mathbf{H}^t$ by~\eqref{eq::modBBcostMatrix}~\eqref{eq::infColumn} \\
 \For{$i \in \mathcal{I}^t$}
 {
 	Add the cost for I-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + h_{ii}^t$ \\
 }
 \For{$j \in V \setminus \mathcal{I}^t$}
 {
 	Add the cost for candidate P-frame cameras $lb(\mathcal{S}^t) \gets lb(\mathcal{S}^t) + \underset{k \in V \setminus \mathcal{P}^t}{\min} h_{jk}^t$ \\
 }
 \caption{\label{alg::lbEstimation_baseline}Baseline lower bound estimation method}
\end{algorithm}
\DecMargin{1em}
%

Note that the lower bound obtained by algorithm~\ref{alg::lbEstimation_baseline} is a loose bound, since the obtained cost might refer to an infeasible reference structure (i.e. $i$ reference $j$ together with $j$ reference $i$).
Therefore, we can claim that our proposed lower bound estimation method can reduce more computational complexity than the baseline approach.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/compareLbEstimation.pdf}
\caption{\label{fig::compareLbEstimation} Comparison of convergence speed for different lower bound estimation methods}
\end{center}
\end{figure}
%
As shown in Fig.~\ref{fig::compareLbEstimation}, although the two algorithms converge to the same optimal objective value, the required iterations for convergence for those two approaches are definitely different.
That is, more than $98\%$ of iterations can be further reduced if our proposed lower bound estimation technique is applied.
The results thus confirm us that the lower bound estimated by algorithm~\ref{alg::lbEstimation} is a tighter bound so that the optimal solution can be found under lower computational complexity.

%Fig.~\ref{fig::evaNumActiveBBNodes} further shows the number of unpruned nodes for the BB algorithm.
%We can learn in this figure that although the maximum number of active BB nodes for the two lower bound estimation algorithms are equalled, our proposed method can decrease faster than the baseline approach.
%More specifically, the number of active BB nodes will first increase exponentially at the beginning of the algorithm, and start to decrease when the objective upper bound becomes smaller.
%That is, as long as the objective upper bound becomes smaller, more branches can be pruned and hence the number of unpruned nodes will not increase back to the original level.
%Besides, note that in Fig.~\ref{fig::evaNumActiveBBNodes}, our proposed method decrease faster, this is due to the reason that our estimated lower bound is a tighter bound and hence more branches can be pruned.

%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/complexity2.pdf}
\caption{\label{fig::complexity} Required iterations for convergence}
\end{center}
\end{figure}
%
For the evaluation results about time complexity, Fig.~\ref{fig::complexity} further shows the required iterations for convergence by changing the number of cameras $|V|$ in the network.
Note that for the worst case, BB algorithm needs to traverse at most $2^{|V|}$ branches to ensure that the obtained solution is optimal.
Consequently, the time complexity of BB algorithm will increase exponentially as the network size becomes larger, which is matched as the result in Fig.~\ref{fig::complexity}.
However, since our proposed lower bound estimation algorithm can achieve a tighter bound, more branches can be pruned in this way, and hence the slope of complexity increment of our method is smaller than both brute force and baseline approach.
Smaller slope for complexity increment will lead to a considerable performance gain when the network size $|V|$ becomes large.
That is, when the number of cameras is $30$, our method can reduce $99\%$ compared to brute force approach and reduce $98\%$ compared to baseline lower bound estimation method.
%
\subsection{Evaluation of Different I-frame Selection Algorithms}
%{\color{red}Show the evaluation result of different I-frame selection algorithms (BB, proposed MDS, baseline MDS~\cite{MWDS_baseline}).}
In this chapter, we show the evaluation results of different I-frame selection algorithms, including the proposed BB algorithm, proposed graph approximation algorithm, and the baseline MDS algorithm~\cite{MWDS_baseline}.
To start, we first show the performance gain of overhearing source coding for the three algorithms above.
That is, our proposed BB algorithm and graph approximation method is compared with a baseline MDS algorithm, where the baseline MDS algorithm is proposed in~\cite{MWDS_baseline}.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/txBytes_diffAlg2.pdf}
\caption{\label{fig::txBytes_diffAlg} Comparison of different I-frame selection algorithms}
\end{center}
\end{figure}
%
The obtained results in shown in Fig.~\ref{fig::txBytes_diffAlg}, where the reduction of transmission bits is $11\%$ for the BB algorithm and $10\%$ for the graph approximation method.
However, only $1\%$ of transmission bits can be reduced if the MDS algorithm~\cite{MWDS_baseline} is applied.
This is because their method only consider the cost of I-frame cameras.
That is, they aim to select the set of I-frame cameras such that the total amount of encoded bits required to deliver those I-frame can be minimized.
However, in reality, the cost of P-frame cameras cannot be ignored, and hence the result of~\cite{MWDS_baseline} will lead to sub-optimal in our scenario.

%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/struMDS_b.pdf}
\caption{\label{fig::refStructure_MDSbaseline} Baseline MDS algorithm}
\end{subfigure}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/struMDS_p.pdf}
\caption{\label{fig::refStructure_MDSproposed} Proposed MDS algorithm}
\end{subfigure}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/struBB.pdf}
\caption{\label{fig::refStructure_BB} Proposed BB algorithm}
\end{subfigure}
\caption{\label{fig::refStructure_threeAlgs} Selected I-frame cameras and their member P-frame cameras}
\end{center}
\end{figure}
%
Fig.~\ref{fig::refStructure_threeAlgs} further demonstrates the I-frame cameras sets and their corresponding P-frame camera members obtained by the three algorithms, where different color in Fig.~\ref{fig::refStructure_threeAlgs} indicates different cameras group.
According to the results of Fig.~\ref{fig::refStructure_threeAlgs}, it seems that the baseline MDS approach obtains a good result since it tends to select neighboring cameras into the same group.
However, note that the inherent difference between camera devices and scalar sensor devices is that not only their position but also their sensing direction will affect the correlation among camera devices.
Therefore, grouping nearby cameras might not be a good choice.
For example, camera $22$ and $28$ are within the same group if the baseline MDS algorithm is applied.
However, these two cameras are observing opposite directions and hence their captured images are thought to be definitely different.
Our two proposed I-frame selection algorithms, on the other hand, will divide camera $22$ and $28$ into different groups.
From the results of Fig.~\ref{fig::txBytes_diffAlg}, both these two proposed methods can outperform baseline MDS algorithm, and hence confirm us the sensing direction of each camera cannot be neglected in the scenario of multi-camera networks.


\subsection{Evaluation of Different Overhearing Range}
%{\color{red}Show the evaluation result of different overhearing range.}
For the overhearing range parameter $\rho$, we are also interested in how this parameter will influence the performance of the overhearing source coding mechanism.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/overRange.pdf}
\caption{\label{fig::evaOverRange}Evaluation of different overhearing range parameter $\rho$}
\end{center}
\end{figure}
%
Note that if the BB algorithm is applied, since optimal solution is promised to obtained through this algorithm, it is thus clearly that the performance gain will becomes larger as $\rho$ increases, which is shown in the red line of Fig.~\ref{fig::evaOverRange}.
Unfortunately, the graph approximation method does not have this property.
That is, as shown in the blue line of Fig.~\ref{fig::evaOverRange}, the improvement ratio of $\rho = 0.4$ becomes even worse than $\rho = 0.2$.
This is because we refer to a heuristic approach when selecting I-frame cameras in the graph approximation algorithm.
Therefore, when $\rho$ becomes larger, the metrics~\eqref{eq::IFrameSelectionMetric} of each cameras are changed and hence although sometimes the graph approximation method can perform very well (e.g. $\rho = 0.2,0.6,0.8$), but it will also sometimes lead to sub-optimal solution since greedily using metric~\eqref{eq::IFrameSelectionMetric} might select improper I-frame cameras.
For the baseline MDS algorithm~\cite{MWDS_baseline}, the improvement ratio becomes saturated very quickly since it only considers the cost of I-frame cameras.
Therefore, increasing $\rho$ does not benefit the performance of this algorithm due to the reason that it tends to select less I-frame cameras, and hence the selected I-frame cameras might not be correlated with the remaining P-frame cameras.

\subsection{Evaluation of Multiple Transmission Rounds}
%

For real-world multi-camera applications, each camera will transmit video streams instead of only one isolated video frame.
As a consequence, in this chapter, we consider the scenario that each camera will transmit its video frames sequentially for multiple transmission round, where the definition of ``one transmission round'' is presented in Chapter~\ref{sec::overallSystemArchi}.
Assume that the scenario we considered has $10$ transmission round, which means that each camera is required to deliver $10$ I-frames to the data aggregator.
Since different transmission rounds mean we make observation at different time instance, it is clearly that the video frames captured by each camera will become different at different transmission round.
In addition, the exact cost matrix will also be changed for different transmission round.
Due to the reasons described above, the improvement ratio of our proposed correlated data gathering scheme (either the branch-and-bound method or the graph approximation approach) will vary as the transmission round changes.

%
%\ignore{
\begin{figure}
\begin{center}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam3Slot1}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam4Slot1}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam5Slot1}
\caption{Round 1}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam3Slot7}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam4Slot7}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam5Slot7}
\caption{Round 2}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam3Slot3}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam4Slot3}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam5Slot3}
\caption{Round 3}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam3Slot5}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam4Slot5}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam5Slot5}
\caption{Round 4}
\end{subfigure}
%
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam3Slot4}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam4Slot4}
\includegraphics[width=0.32\columnwidth]{Figures/multiSlots/cam5Slot4}
\caption{Round 5}
\end{subfigure}
\caption{\label{fig::imgCapMultiSlots} Image captured at different transmission round}
\end{center}
\end{figure}
%} % end ignore
%
We now consider a scenario having $10$ cameras deployed at intersections of a city,
where the captured video snapshots of two cameras at different transmission round is shown in Fig.~\ref{fig::imgCapMultiSlots}.
Three different criteria for dealing with the cost matrix $\mathbf{H}$~\eqref{eq::bbCostMatrix} are now compared in this chapter.
The idea of three different criteria are listed below:
\begin{itemize}
\item \textbf{Static cost matrix}: Indicate the case that the cost matrix does not modified as the transmission round changes.
That is, the data aggregator only calculates the cost matrix for the first transmission round, and the obtained cost matrix will be used for the following $9$ transmission round.
The advantage of this criterion is that it has the lowest computational complexity at the data aggregator since it only requires calculating cost matrix and scheduling cameras once.
However, outdated cost matrix will decrease the performance of our proposed data gathering scheme.
\item \textbf{Dynamic cost matrix (baseline)}: Indicate the case that the cost matrix is dynamically being modified as the transmission round changes, where baseline means that our proposed reestimation criteria introduced in Chapter~\ref{sec::reestimationCriteria} has not been applied.
Therefore, the data aggregator will use a multiview encoder for updating the cost matrix each time when a transmission round is terminated.
The advantage of this criterion is that it can adapt to the scenario that the video streams change rapidly since the cost matrix is updated round by round.
However, frequently calculating cost matrix will lead to very high computational complexity at the data aggregator.
\item \textbf{Dynamic cost matrix (proposed)}:
Indicate the case that the cost matrix is dynamically being modified at some transmission rounds, where the reestimation criteria introduced in Chapter~\ref{sec::reestimationCriteria} is applied for this case.
Intuitively speaking, this case can achieve better performance than static cost matrix and also has lower computational complexity compared to baseline dynamic cost matrix.
\end{itemize}

%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/evaMultiSlots2.pdf}
\caption{\label{fig::evaMultiSlots}Evaluation of improvement ratio for different transmission round}
\end{center}
\end{figure}
%
Fig.~\ref{fig::evaMultiSlots} thus confirms our claim of advantages and disadvantages for the above three cases.
Both the results of branch-and-bound algorithm and graph approximation algorithm are shown in this figure.
For the graph approximation algorithm, since it is a heuristic approach and hence it is not promised to obtain the optimal solution.
Therefore, we can observe in Fig.~\ref{fig::evaMultiSlots} that although the performance of graph approximation can sometimes be very closed to the performance of branch-and-bound algorithm, it happens that there exists a considerable performance gap between these two methods at some transmission round (e.g. round $1$).
Let us now focus on the variation of improvement ratio, it is clearly that the baseline dynamic cost matrix is the upper bound for the improvement ratio since it updates $\mathbf{H}$ for every transmission round.
On the other hand, using static cost matrix is the lower bound for the improvement ratio and we can observe in Fig.~\ref{fig::evaMultiSlots} that the performance for this case become very bad after round $2$.
However, as long as the improvement ratio decrease badly at round $2$, the long term improvement ratio $\bar{\eta}$~\eqref{eq::updateEta} will decrease.
The decrease of $\bar{\eta}$ will trigger the reestimation of $\mathbf{H}$ so that the performance can be recovered at round $3$.
For the same reason, the result in Fig.~\ref{fig::evaMultiSlots} indicates that the performance will recover to the ``best'' performance in the next transmission round if the improvement ratio becomes lower than a threshold.

In addition to comparing the improvement ratio for the three criteria, we are also interested in the computational cost of these approaches.
Clearly, the computational cost for the case of static cost matrix is the lowest, since it only requires calculating the cost matrix $\mathbf{H}$ once.
Therefore, only the cases that use dynamic cost matrix are taken into comparison in this chapter.
%
\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Figures/cmuExecTime.pdf}
\caption{\label{fig::evaExecTime}Evaluation of cumulative execution time for different algorithms}
\end{center}
\end{figure}
%
Fig.~\ref{fig::evaExecTime} thus shows the cumulative execution time of the two approaches using dynamic cost matrix, where both BB algorithm and graph approximation method are considered.
For the two baseline approaches (i.e. red lines in Fig.~\ref{fig::evaExecTime}), since the cost matrix is updated after each time a transmission round is ended, the cumulative execution time will increase for every transmission round.
Our proposed methods (i.e. blue lines in Fig.~\ref{fig::evaExecTime}), on the other hand, does not recalculate the cost matrix that often.
Therefore, the cumulative execution time only increases when the TS phase is triggered by the long term improvement ratio $\bar{\eta}$.
Since only round $3$ and $7$ performs the TS phase, the cumulative execution thus increases twice in these two transmission rounds as shown in Fig.~\ref{fig::evaExecTime}.
Note that although the BB algorithm is thought to be more complicated than the graph approximation method, the result in Fig.~\ref{fig::evaExecTime} shows that the cumulative execution time of using BB algorithm together with the proposed reestimation criterion is even smaller than using graph approximation together with updating the cost matrix every transmission round.
Therefore, we can thus claim that it is necessary to use a proper reestimation criterion instead of greedily updating the cost matrix.

\subsection{Evaluation of Received Video Quality}
%{\color{red}Show the evaluation results for image quality of different transmission round.}
As we shown in Fig.~\ref{fig::multiViewImageDemo} before, multiview encoding can be regard as a near lossless video compression technique.
Therefore, in this chapter, we show the evaluation results about the average quality of received videos at the data aggregator with and without the use of overhearing source coding, where the scenario we considered is the same with Fig.~\ref{fig::evaMultiSlots}~and~\ref{fig::evaExecTime}.
For the independent encoding (i.e. without the use of overhearing source coding), each camera will transmit the original sequence of video frames.
Therefore, the GOP of all cameras will start with an I-frame, and we calculate the average PSNR of those I-frames reconstructed at the data aggregator to represent the video quality of the independent encoding scheme, where PSNR is a commonly used metric for evaluating the video quality defined as~\cite{PSNRDef}:
\begin{equation}
\text{PSNR} = 10 \cdot \log \left( \frac{\text{MAX}^2_i}{\text{MSE}} \right),
\end{equation}
with $\text{MAX}_i$ being the maximum pixel value of the image and $\text{MSE}$ being the mean-squared error.
%
For the overhearing encoding, some cameras have the possibility to encode their I-frames as P-frames.
Therefore, we use a multiview encoder and decoder to experimentally obtain the reconstructed PSNR of those I-frames.
More specifically, if a camera is selected as an I-frame camera, then its reconstructed PSNR is equalled to using the independent encoding scheme.
However, if a camera is not selected as an I-frame camera (i.e. encode as a P-frame), then we will first reconstruct its reference I-frame and then use JMVC~\cite{JMVC} to reconstruct this P-frame and calculate its PSNR.

%
\begin{figure}
\begin{center}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=0.95\columnwidth]{Figures/evaAllPSNR.pdf}
\caption{\label{fig::evaAllPSNR}}
\end{subfigure}
\begin{subfigure}[b]{\columnwidth}
\includegraphics[width=\columnwidth]{Figures/evaPartialPSNR.pdf}
\caption{\label{fig::evaPartialPSNR}}
\end{subfigure}
\caption{\label{fig::evaMultiRunPSNR} PSNR for reconstructed video frames}
\end{center}
\end{figure}
%
Using the above method, the average PSNR of each transmission round is shown in Fig.~\ref{fig::evaMultiRunPSNR}, where we can learn in this figure that the video quality of overhearing encoding is very closed to the independent encoding scheme.
If we take a more detailed observation, the gap of PSNR of those two approaches is less than $0.01$.
Therefore, we can claim that although the amount of encoded bits in our proposed scheme is much more smaller than independent source coding, the overhearing source coding method does not decrease the quality of received video.
As a consequence, this result thus motivates us to apply the overhearing source coding scheme into the applications of multi-camera networks, especially when the network is under \emph{tight radio resource constraints}.

%\subsection{Evaluation of Modified Motion Estimation}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.95\columnwidth]{Figures/biased.pdf}
%\caption{\label{fig::biased}Evaluation result for modified motion estimation}
%\end{center}
%\end{figure}
%Fig.~\ref{fig::biased}